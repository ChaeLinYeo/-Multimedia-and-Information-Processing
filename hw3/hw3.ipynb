{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import math\n",
    "\n",
    "# 주성분분석(Principal Component Analysis)을 하기 위한 라이브러리\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# 파일 경로 확인용\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# .py 파일 가져오기\n",
    "# import (폴더이름.)파일이름\n",
    "import src.facenet as facenet\n",
    "import src.align.detect_face as detect_face\n",
    "\n",
    "# jupyter notebook 펭지에 그리기\n",
    "%matplotlib inline\n",
    "\n",
    "# 학습되어 있는 모델을로드하는 함수\n",
    "# 입력 : protobuf 파일(모델이 정의되어 있음)\n",
    "# 리턴 :\n",
    "#     - single_image : 영상을 입력하는 placeholder (session, run feed_dict 에 사용)\n",
    "#     - embeddings : 네트어크의 출력 값, 512차원의 추출된 얼굴 특징 벡터\n",
    "\n",
    "def load_model(pb_path, image_size=(160,160)) :\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    single_image = tf.placeholder(tf.int32, (None, None, 3))\n",
    "    float_image = tf.cast(single_image, tf.float32)\n",
    "    float_image = float_image/255\n",
    "    batch_image = tf.expand_dims(float_image, 0)\n",
    "    resized_image = tf.image.resize(batch_image, image_size)\n",
    "    \n",
    "    phase_train = tf.placeholder_with_default(False, shape=[])\n",
    "    \n",
    "    input_map = {'image_batch' : resized_image, 'phase_train' : phase_train}\n",
    "    model = facenet.load_model(pb_path, input_map)\n",
    "    \n",
    "    embeddings = tf.get_default_graph().get_tensor_by_name(\"embeddings: 0\")\n",
    "    \n",
    "    return single_image, embeddings\n",
    "\n",
    "# 영상 경로를 입력받아 로드하고, return해주는 함수\n",
    "def load_image(image_path) :\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    return image\n",
    "\n",
    "# 두 벡터간의 거리를 계산하는 함수\n",
    "\n",
    "def calc_distance(embedding1, embedding2) :\n",
    "    # Euclidian distance\n",
    "    diff = np.subtract(embedding1, embedding2)\n",
    "    dist = np.sum(np.square(diff), 0)\n",
    "    \n",
    "    return dist\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model filename: ./models/20180402-114759.pb\n",
      "WARNING:tensorflow:From /Users/macbook/Desktop/Week9+hw3/src/facenet.py:371: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n",
      "WARNING:tensorflow:From /Users/macbook/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/macbook/Desktop/Week9+hw3/src/align/detect_face.py:213: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "(40, 512)\n",
      "[ 9.44873840e-02  2.47697737e-02 -3.28789023e-03  5.33525161e-02\n",
      "  2.19947174e-02 -2.26591974e-02 -4.75082658e-02  2.05385331e-02\n",
      " -1.40227228e-02 -4.23607565e-02  4.05533537e-02  2.08814139e-03\n",
      "  4.13690973e-03  2.73972321e-02  1.75733101e-02 -9.56316069e-02\n",
      "  2.53071031e-03  5.79846650e-03  4.57997955e-02  4.97211926e-02\n",
      "  9.41700488e-03 -2.47731134e-02  5.26755117e-02 -1.01825364e-01\n",
      "  3.96296661e-03 -5.24287811e-03  8.91560167e-02 -2.11817585e-02\n",
      "  5.38082756e-02 -1.29293082e-02  5.10510430e-02  2.86690407e-02\n",
      " -5.19351549e-02  1.75030529e-02 -6.85283123e-03 -6.71764314e-02\n",
      " -6.02130331e-02 -1.64456461e-02 -4.29300256e-02  3.57171372e-02\n",
      " -8.00881386e-02  7.71067431e-03 -1.68482668e-03  3.72561254e-02\n",
      " -7.24110240e-03 -3.58745754e-02  4.46822494e-02  6.21395484e-02\n",
      " -6.40783459e-02 -4.63866629e-02 -8.56808294e-03 -6.91591427e-02\n",
      "  5.99515811e-02  4.09698188e-02 -4.74792812e-03  2.47490406e-02\n",
      " -5.32646151e-03  7.82664120e-02 -1.55618312e-02 -1.00191515e-02\n",
      " -4.09521759e-02  4.01014797e-02 -2.68752538e-02  2.74920668e-02\n",
      "  6.07344136e-02  2.44583488e-02 -1.52044091e-02 -6.43038154e-02\n",
      " -4.97322762e-03 -9.05311853e-02  2.06801016e-02  5.24970815e-02\n",
      " -2.27312390e-02 -1.62685774e-02 -4.89983931e-02 -4.95216623e-02\n",
      "  3.17732431e-02 -1.11547299e-01 -7.74165057e-03  2.36011948e-02\n",
      "  5.21265492e-02  4.34890054e-02  1.71596464e-02  3.59051451e-02\n",
      "  2.44452916e-02  3.90411429e-02 -4.36920226e-02 -1.15580717e-02\n",
      "  2.65486725e-02  7.69442990e-02  6.12272657e-02  3.59668396e-02\n",
      "  3.69509645e-02 -1.26159742e-01  4.29056622e-02  3.41966189e-02\n",
      " -3.99147086e-02  1.03627294e-01 -4.55924571e-02 -4.19201665e-02\n",
      "  4.53565605e-02  1.35909328e-02  2.87708510e-02  5.48157729e-02\n",
      "  2.42504440e-02  5.56835458e-02  3.54545303e-02  8.97977035e-03\n",
      " -4.37986255e-02  5.45925461e-03  5.33477664e-02  1.65881738e-02\n",
      " -5.79010416e-03 -1.12265898e-02 -7.04550743e-02  8.43217305e-04\n",
      "  1.90245267e-03  5.40528856e-02  1.82206109e-02  7.74213597e-02\n",
      " -5.67767099e-02  2.00745203e-02  5.28304428e-02 -3.41038816e-02\n",
      " -7.34145790e-02 -3.86522450e-02  6.88905269e-02 -9.72829014e-02\n",
      " -6.24454161e-03 -4.17679958e-02 -1.67656541e-02  6.99305013e-02\n",
      "  2.89505795e-02  1.14625751e-03 -1.82726830e-02  4.81688604e-02\n",
      " -4.88512106e-02 -1.52135249e-02  2.03856751e-02  4.50236388e-02\n",
      " -2.06628647e-02  3.12264413e-02 -9.19852927e-02 -1.56428330e-02\n",
      "  1.14158690e-02  3.29024978e-02 -7.68448925e-03  2.03425754e-02\n",
      "  4.97629642e-02  1.91395357e-02  1.13082297e-01  8.07579309e-02\n",
      " -6.18380345e-02  8.20514187e-02 -5.22613525e-03  4.58149053e-02\n",
      " -1.84060801e-02 -3.48106772e-02 -4.72753588e-03 -3.90966125e-02\n",
      "  7.81199560e-02  6.45384798e-03  2.16015298e-02 -2.22895527e-03\n",
      "  1.33428560e-03 -2.25935294e-03 -3.08091361e-02 -6.99965144e-03\n",
      " -8.45261514e-02  2.87271384e-02 -4.83065173e-02 -1.08740842e-02\n",
      " -1.45786880e-02 -5.88777550e-02  9.68249515e-03  1.82627467e-03\n",
      " -6.84308037e-02 -3.05937007e-02  3.47486348e-03  1.63989142e-02\n",
      "  1.95752960e-02  2.71938611e-02 -8.02513957e-02 -4.32123290e-03\n",
      "  4.97982663e-04  5.99669144e-02  2.65036616e-02  6.69580251e-02\n",
      "  3.33758593e-02  6.56365082e-02  1.85625013e-02  5.95795410e-03\n",
      "  2.24758424e-02 -2.30669938e-02  3.57967652e-02  6.64012060e-02\n",
      " -6.27338886e-02  2.23421870e-04  4.61568218e-03 -8.93626269e-03\n",
      "  4.71845567e-02 -4.98481020e-02 -2.91921310e-02  3.80398706e-02\n",
      "  7.05961585e-02  4.58473116e-02  5.25732338e-03 -1.34493224e-03\n",
      "  2.19461434e-02  4.21684682e-02 -4.34689187e-02 -1.67929344e-02\n",
      " -3.95521801e-03 -3.70000210e-03 -9.23345461e-02 -1.47785069e-02\n",
      " -4.46292385e-03  5.26595190e-02  5.50467614e-03  5.06167449e-02\n",
      " -7.23424852e-02 -3.92151177e-02  2.59404480e-02  2.20394339e-02\n",
      "  2.20351834e-02  1.02743983e-01  1.32053280e-02  3.17697525e-02\n",
      " -6.32323548e-02 -1.42278625e-02  6.94349930e-02 -7.35601279e-05\n",
      "  1.15691787e-02 -3.16799991e-02 -2.31497735e-02 -4.67998162e-02\n",
      " -5.26833422e-02  1.50445979e-02  4.11202386e-02 -1.24029368e-02\n",
      " -3.07885986e-02 -2.66770255e-02 -1.19992709e-02 -2.54210066e-02\n",
      " -2.97359517e-03  2.18021385e-02 -1.08587191e-01 -2.46953908e-02\n",
      " -1.60113182e-02  8.15280303e-02 -2.65118461e-02  8.00172973e-04\n",
      "  1.32987099e-02  4.21329867e-03 -2.58349478e-02  3.31979468e-02\n",
      "  1.76567361e-02  8.20769891e-02  7.97358006e-02 -4.29397449e-02\n",
      " -4.23738249e-02 -9.17309523e-03  9.78049338e-02 -6.83029601e-03\n",
      "  3.83010022e-02  2.36531231e-03  1.41333714e-02  1.85159091e-02\n",
      "  3.02341282e-02  3.89170647e-03 -1.15537958e-03  2.45791413e-02\n",
      "  6.46549389e-02  3.01297475e-03 -5.51331490e-02  5.22496216e-02\n",
      "  1.77768990e-02  1.55067127e-02  7.49997655e-03  6.91186870e-03\n",
      " -1.51329366e-02  6.20682202e-02 -2.44299583e-02 -2.84068435e-02\n",
      " -3.36981714e-02 -3.32126543e-02 -6.69127214e-04 -4.10639495e-03\n",
      "  3.02592982e-02  2.14313325e-02  3.87000740e-02 -5.76152280e-02\n",
      " -2.77946927e-02  1.14002423e-02 -4.76140045e-02 -5.41021675e-02\n",
      " -6.09021634e-03 -2.78510489e-02 -2.84568476e-03 -4.48557101e-02\n",
      " -3.98827717e-02  2.72556711e-02 -4.69914861e-02 -5.25747426e-02\n",
      "  7.00863823e-02 -1.20312795e-02 -1.76028032e-02  7.81142861e-02\n",
      " -6.63803667e-02  6.64217547e-02 -6.87981173e-02  4.05930281e-02\n",
      "  3.66494549e-03  6.49362057e-02  2.79866159e-02  4.40283455e-02\n",
      " -4.59874608e-02 -2.35842243e-02  4.53509279e-02  7.51079917e-02\n",
      "  4.45105210e-02 -1.86705813e-02  1.63183399e-02  5.31845428e-02\n",
      "  5.84220514e-02 -2.49799825e-02  6.99816495e-02  8.31965506e-02\n",
      "  1.69028691e-03  1.18051539e-03  2.46707499e-02  6.17953390e-02\n",
      " -3.39809097e-02  2.18052492e-02  1.09643107e-02 -2.69722361e-02\n",
      " -1.74731668e-02 -2.83458214e-02  6.47651637e-03 -3.15314755e-02\n",
      "  4.90818135e-02  3.40454988e-02 -2.74393242e-02 -5.51324524e-03\n",
      " -1.75458863e-02  7.25763962e-02  2.12670136e-02  1.88070573e-02\n",
      "  3.57744694e-02  1.94733571e-02 -2.82124989e-03 -2.99458206e-02\n",
      "  5.48808090e-02 -5.62357157e-02 -3.14939432e-02 -2.91512646e-02\n",
      "  3.39197554e-02  3.51164453e-02  2.95374878e-02  3.82047123e-03\n",
      "  1.47229964e-02 -6.26522303e-02 -4.24987487e-02 -1.38580529e-02\n",
      "  4.66340818e-02 -3.31242271e-02 -2.65812036e-03 -1.20385535e-01\n",
      "  8.90901871e-03  1.19029721e-02 -1.03605382e-01 -5.79127632e-02\n",
      " -4.00666259e-02  2.06286460e-02  3.19248773e-02  9.24289152e-02\n",
      " -3.29459226e-03  5.90636358e-02 -2.52435706e-03  3.33931111e-02\n",
      " -3.94312963e-02 -1.00165427e-01 -5.90649433e-02 -3.01533882e-02\n",
      " -3.57637592e-02 -2.22172569e-02  1.49353901e-02  6.39591143e-02\n",
      "  7.46553345e-03 -3.09439600e-02 -3.66193578e-02  2.21670046e-02\n",
      " -1.50747690e-02  1.02396356e-02  1.20352291e-01  4.54768501e-02\n",
      " -1.74794123e-02  9.44615453e-02  1.83788594e-02 -5.53240366e-02\n",
      " -2.35998016e-02  5.47462236e-03  3.05710249e-02 -1.85039453e-02\n",
      "  2.70070732e-02  3.45041640e-02 -1.05183929e-01 -2.99300011e-02\n",
      "  3.01911067e-02 -2.73952540e-02  4.27542925e-02  2.83051040e-02\n",
      " -2.90406905e-02 -2.02285666e-02  1.73468497e-02 -3.99835892e-02\n",
      "  5.57953194e-02  8.14597085e-02 -4.11349013e-02 -1.37664294e-02\n",
      "  9.14959470e-04  5.67007549e-02 -1.33232363e-02  9.50013548e-02\n",
      "  6.04354497e-03 -1.10279787e-02 -3.92546467e-02  2.28614192e-02\n",
      "  7.40749985e-02 -3.49551402e-02 -3.52663808e-02  4.91081458e-03\n",
      "  2.55072210e-02 -2.98216799e-03 -4.64258082e-02  1.71979051e-02\n",
      " -4.80977371e-02 -7.64092952e-02 -1.58541799e-02 -4.02251743e-02\n",
      "  2.53920257e-02 -4.92314473e-02  9.09661409e-03  2.93511096e-02\n",
      "  7.57557433e-03  9.37341303e-02  5.70418267e-03  1.90116819e-02\n",
      " -3.70584577e-02 -4.47433721e-03  2.99841110e-02  6.61242604e-02\n",
      " -2.74235127e-03 -3.55224870e-02  4.26910557e-02  3.25144120e-02\n",
      " -2.08062828e-02  1.36778541e-02  1.10185452e-01 -1.44546060e-02\n",
      "  3.16705666e-02  2.27056071e-02 -5.97036332e-02 -1.06915133e-02\n",
      " -3.39603722e-02 -4.78475504e-02 -2.00264733e-02  3.42321172e-02\n",
      "  5.43961599e-02  1.00629486e-01  2.32589301e-02  3.30838487e-02\n",
      "  9.20953676e-02 -5.25892936e-02 -1.35223502e-02 -4.13728096e-02\n",
      "  1.54032502e-02 -1.57263763e-02 -2.85509657e-02  4.53729089e-03\n",
      " -1.20804282e-02  5.09515516e-02  5.27821183e-02  7.06225187e-02\n",
      " -5.83153553e-02 -3.56685114e-03 -4.72988598e-02  1.28031075e-01\n",
      "  3.25888433e-02 -4.02079523e-02 -2.13435050e-02 -5.05842008e-02\n",
      " -6.67859092e-02  7.08014518e-03 -1.02334248e-03 -3.92848738e-02\n",
      "  2.05619130e-02 -3.70073430e-02  4.55853269e-02 -2.05764454e-02\n",
      " -2.35590152e-02 -4.76866141e-02 -7.84950107e-02 -3.17331031e-03\n",
      " -4.25576642e-02  2.81109940e-02  4.66143247e-03 -2.44536414e-03\n",
      " -8.17442089e-02 -2.31871307e-02  7.97082707e-02 -1.55650163e-02]\n"
     ]
    }
   ],
   "source": [
    "#############과제##############\n",
    "# 사용함수 \n",
    "# calc_distance (두 벡터간의 거리 계산 함수. 서로 다른 두 얼굴의 특징벡터간 거리.)\n",
    "# detect_face.creat_mtcnn ()\n",
    "# load_model\n",
    "\n",
    "tf.reset_default_graph()\n",
    " \n",
    "single_image, embeddings = load_model(\"./models/20180402-114759.pb\")\n",
    "\n",
    "sess = tf.Session()\n",
    "pnet, rnet, onet = detect_face.create_mtcnn(sess,None)#학습되어 있는 detection 모델 로드\n",
    "\n",
    "\n",
    "################################\n",
    "\n",
    "\n",
    "#내 얼굴의 특징백터 (embedding) 추출\n",
    "path_me = glob.glob(\"./data/faces/chaelin/*\")\n",
    "embed_me = []\n",
    "\n",
    "for path in path_me :\n",
    "    img = load_image(path)\n",
    "    result = sess.run(embeddings, feed_dict={single_image : img})\n",
    "    result = result[0]\n",
    "    embed_me.append(result)\n",
    "\n",
    "embed_me = np.array(embed_me)\n",
    "print(embed_me.shape)\n",
    "\n",
    "# 첫 번째 얼굴 사진의 특징벡터 확인\n",
    "print(embed_me[0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def video2frame(invideofilename, save_path):\n",
    "#     vidcap = cv2.VideoCapture(invideofilename)\n",
    "#     count = 0\n",
    "#     while True:\n",
    "#       success,image = vidcap.read()\n",
    "#       if not success:\n",
    "#           break\n",
    "#       print ('Read a new frame: ', success)\n",
    "#       fname = \"{}.jpg\".format(\"{0:05d}\".format(count))\n",
    "#       cv2.imwrite(save_path + fname, image) # save frame as JPEG file\n",
    "#       count += 1\n",
    "#     print(\"{} images are extracted in {}.\". format(count, save_path))\n",
    "\n",
    "#출처: https://wondy1128.tistory.com/148 [원도블로그]\n",
    "# invideofilename = \"jimin.mp4\"\n",
    "# save_path = \"./data/faces/others_1/\"\n",
    "# video2frame(invideofilename, save_path)\n",
    "\n",
    "# invideofilename2 = \"sister.mp4\"\n",
    "# save_path2 = \"./data/faces/others_2/\"\n",
    "# video2frame(invideofilename2, save_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105, 512)\n",
      "(136, 512)\n",
      "0.9457369\n",
      "0.7678982\n",
      "-------------- 내 얼굴과의 거리 -------------\n",
      "0.0\n",
      "0.9457369\n",
      "0.8242749\n",
      "0.90482056\n",
      "0.311552\n",
      "0.49317616\n",
      "0.7462913\n",
      "0.753266\n",
      "1.0755973\n",
      "0.89257324\n",
      "0.49057543\n",
      "1.1169876\n",
      "0.60704446\n",
      "0.9538058\n",
      "0.56900907\n",
      "1.0459902\n",
      "0.7632258\n",
      "0.52442366\n",
      "0.35327268\n",
      "0.7781031\n",
      "0.5607554\n",
      "0.8978255\n",
      "1.2458984\n",
      "0.78194535\n",
      "0.7081838\n",
      "0.52261734\n",
      "1.0326482\n",
      "1.0419719\n",
      "0.7076865\n",
      "0.59649587\n",
      "0.83971405\n",
      "0.65689814\n",
      "0.7781309\n",
      "0.62029386\n",
      "0.82030034\n",
      "0.7305293\n",
      "1.0647469\n",
      "0.84844327\n",
      "0.24663427\n",
      "0.9630339\n",
      "\n",
      "\n",
      "\n",
      "------------ 다른 사람 얼굴과의 거리 --------------\n",
      "0.7678982\n",
      "0.82205534\n",
      "0.7539915\n",
      "1.0719757\n",
      "1.057755\n",
      "0.69507474\n",
      "0.8122891\n",
      "0.7919638\n",
      "0.84567416\n",
      "0.80660474\n",
      "0.9248714\n",
      "0.9761412\n",
      "0.807403\n",
      "0.93415475\n",
      "0.9871917\n",
      "0.71006346\n",
      "0.81089604\n",
      "0.8362377\n",
      "0.7018699\n",
      "0.7726028\n",
      "0.7913676\n",
      "0.69016635\n",
      "0.8462998\n",
      "0.8435762\n",
      "0.72872174\n",
      "0.79261386\n",
      "0.71227056\n",
      "0.68257564\n",
      "0.76872003\n",
      "0.6394317\n",
      "1.0893853\n",
      "0.9829288\n",
      "0.8006226\n",
      "1.0006862\n",
      "0.7079828\n",
      "0.78421044\n",
      "0.71160024\n",
      "0.69450223\n",
      "0.762025\n",
      "0.7247275\n",
      "0.7312366\n",
      "0.684765\n",
      "0.7452743\n",
      "0.71540534\n",
      "0.7183632\n",
      "0.75268275\n",
      "0.76220787\n",
      "0.69235325\n",
      "0.7154999\n",
      "0.6899756\n",
      "0.79970026\n",
      "0.75926745\n",
      "0.70090085\n",
      "0.6667223\n",
      "0.76860434\n",
      "0.81608963\n",
      "0.7496047\n",
      "0.81040967\n",
      "0.7749854\n",
      "0.7553362\n",
      "0.7945231\n",
      "0.76365817\n",
      "0.71570265\n",
      "0.78439206\n",
      "0.7764402\n",
      "0.7915752\n",
      "0.74718404\n",
      "0.79693025\n",
      "0.76973724\n",
      "0.75550956\n",
      "0.7584522\n",
      "0.7410192\n",
      "0.71582484\n",
      "0.70806193\n",
      "0.7405568\n",
      "0.75204253\n",
      "0.746318\n",
      "0.9265711\n",
      "0.8607718\n",
      "0.91205215\n",
      "0.95710003\n",
      "0.87963307\n",
      "0.7499801\n",
      "0.7291505\n",
      "0.74089694\n",
      "0.79480296\n",
      "0.7643152\n",
      "0.9644058\n",
      "0.7637512\n",
      "0.95678455\n",
      "0.80567\n",
      "0.7643045\n",
      "0.6704616\n",
      "0.77322614\n",
      "0.81579316\n",
      "0.7979661\n",
      "1.200619\n",
      "0.6704243\n",
      "0.70627075\n",
      "0.7404295\n",
      "1.0703804\n",
      "0.92808306\n",
      "0.7139054\n",
      "0.67963326\n",
      "0.72626746\n",
      "1.563709\n",
      "1.5746255\n",
      "1.4895769\n",
      "1.5844069\n",
      "1.3458598\n",
      "1.4117779\n",
      "1.3588219\n",
      "1.3173482\n",
      "1.5775745\n",
      "1.4962151\n",
      "1.5953662\n",
      "1.5453732\n",
      "1.5638553\n",
      "1.5994875\n",
      "1.559633\n",
      "1.5524259\n",
      "1.5173335\n",
      "1.2481831\n",
      "1.4400548\n",
      "1.3278797\n",
      "1.2989697\n",
      "1.3783451\n",
      "1.2561035\n",
      "1.6298764\n",
      "1.5398393\n",
      "1.572994\n",
      "1.6198206\n",
      "1.5660703\n",
      "1.5647793\n",
      "1.5562835\n",
      "1.4827878\n",
      "1.5027635\n",
      "1.5632836\n",
      "1.5475729\n",
      "1.297876\n",
      "1.2524695\n",
      "1.2577055\n",
      "1.2416235\n",
      "1.5912894\n",
      "1.5270867\n",
      "1.6049087\n",
      "1.463299\n",
      "1.5509784\n",
      "1.5832034\n",
      "1.5768228\n",
      "1.6137697\n",
      "1.5454584\n",
      "1.3150806\n",
      "1.3399882\n",
      "1.2832848\n",
      "1.2585127\n",
      "1.5420953\n",
      "1.5883219\n",
      "1.5524937\n",
      "1.3660161\n",
      "1.3363433\n",
      "1.367028\n",
      "1.4139856\n",
      "1.3651646\n",
      "1.3569939\n",
      "1.3364043\n",
      "1.3186553\n",
      "1.3145466\n",
      "1.3621802\n",
      "1.3910602\n",
      "1.3355787\n",
      "1.299656\n",
      "1.2318366\n",
      "1.4668319\n",
      "1.3673378\n",
      "1.4070866\n",
      "1.2696359\n",
      "1.3443385\n",
      "1.4577931\n",
      "1.5339706\n",
      "1.4048526\n",
      "1.420105\n",
      "1.4432614\n",
      "1.3914685\n",
      "1.5084662\n",
      "1.4271535\n",
      "1.5091505\n",
      "1.5277381\n",
      "1.4031458\n",
      "1.3118528\n",
      "1.4442264\n",
      "1.4536432\n",
      "1.3647449\n",
      "1.3347495\n",
      "1.4267404\n",
      "1.2954241\n",
      "1.3586372\n",
      "1.4308538\n",
      "1.2853079\n",
      "1.6002083\n",
      "1.5427837\n",
      "1.4282116\n",
      "1.3257866\n",
      "1.2507572\n",
      "1.3285637\n",
      "1.3764892\n",
      "1.4955058\n",
      "1.4504712\n",
      "1.5679657\n",
      "1.4375942\n",
      "1.5548432\n",
      "1.5219545\n",
      "1.50007\n",
      "1.498179\n",
      "1.5376754\n",
      "1.5302147\n",
      "1.397068\n",
      "1.5627801\n",
      "1.3770859\n",
      "1.591937\n",
      "1.3204528\n",
      "1.6126704\n",
      "1.5050237\n",
      "1.26609\n",
      "1.5561278\n",
      "1.509982\n",
      "1.3186873\n",
      "1.4277996\n",
      "1.6179022\n",
      "1.3200045\n",
      "1.6038963\n",
      "1.5890872\n",
      "1.3875415\n",
      "1.5285034\n",
      "1.2634311\n",
      "1.3371462\n",
      "1.2832067\n",
      "1.3106121\n",
      "1.5112754\n",
      "1.3500545\n",
      "1.5854576\n",
      "distance: 1.8140344619750977\n",
      "./data/faces/me/video_bc2_short0_0.jpg 는 내 얼굴이 아닙니다.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#다른 사람 얼굴의 특징벡터 (embedding) 추출\n",
    "path_other1 = glob.glob(\"./data/faces/others_1/*\")\n",
    "\n",
    "embed_other1 = []\n",
    "\n",
    "for path in path_other1:\n",
    "    img = load_image(path)\n",
    "    result = sess.run(embeddings, feed_dict = {single_image : img})\n",
    "    result = result[0]\n",
    "    embed_other1.append(result)\n",
    "    \n",
    "embed_other1 = np.array(embed_other1)\n",
    "print(embed_other1.shape)\n",
    "\n",
    "\n",
    "#다른 사람 얼굴의 특징벡터 (embedding) 추출\n",
    "path_other2 = glob.glob(\"./data/faces/others_2/*\")\n",
    "\n",
    "embed_other2 = []\n",
    "\n",
    "for path in path_other2:\n",
    "    img = load_image(path)\n",
    "    result = sess.run(embeddings, feed_dict = {single_image : img})\n",
    "    result = result[0]\n",
    "    embed_other2.append(result)\n",
    "embed_other2 = np.array(embed_other2)\n",
    "print(embed_other2.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 내 얼굴 1과 내 얼굴 2의 거리 확인\n",
    "print(calc_distance(embed_me[0], embed_me[1]))\n",
    "\n",
    "# 내 얼굴 1과 다른 사람 얼굴 1의 거리 확인\n",
    "print(calc_distance(embed_me[0], embed_other1[0]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 기준이 되는 얼굴 임베딩 설정\n",
    "base_embed = embed_me[0]\n",
    "\n",
    "print(\"-------------- 내 얼굴과의 거리 -------------\")\n",
    "# 얼굴 0~N까지 확인\n",
    "for e in embed_me :\n",
    "    print(calc_distance(base_embed, e))\n",
    "    \n",
    "print(\"\\n\\n\")\n",
    "print(\"------------ 다른 사람 얼굴과의 거리 --------------\")\n",
    "# 다른 사람1, 2를 묶어서 확인\n",
    "embed_others = np.concatenate((embed_other1, embed_other2), axis=0)\n",
    "for e in embed_others :\n",
    "    print(calc_distance(base_embed, e))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#PCA를 사용한 시각화 (512 -> 2차원으로 감소)\n",
    "# 모든 임베딩을 묶음\n",
    "all_embeddings = np.concatenate((embed_me, embed_other1, embed_other2), axis=0)\n",
    "\n",
    "# PCA 클래스 선언 (n_component는 축소할 차원을 의미\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "# PCA 계산 (이후 pca.transform 함수를 사용하여 512차원을 2차원으로 축소)\n",
    "pca.fit(all_embeddings)\n",
    "\n",
    "# PCA를 사용하여 차원 축소\n",
    "xy_me = pca.transform(embed_me)\n",
    "xy_other1 = pca.transform(embed_other1)\n",
    "xy_other2 = pca.transform(embed_other2)\n",
    "\n",
    "ax = plt.figure()\n",
    "\n",
    "sc1 = plt.scatter(xy_me[:,0], xy_me[:,1], color=(1, 0, 0))\n",
    "sc2 = plt.scatter(xy_other1[:,0], xy_other1[:,1], color = (0, 1, 0.4))\n",
    "sc3 = plt.scatter(xy_other2[:,0], xy_other2[:,1], color = (0, 0, 1))\n",
    "\n",
    "plt.legend([sc1, sc2, sc3], [\"me\", \"other1\", \"other2\"], loc = \"upper right\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#내 얼굴인지 분류\n",
    "# 영상 경로를 자유롭게 수정\n",
    "x_path = \"./data/faces/me/video_bc2_short0_0.jpg\"\n",
    "\n",
    "image_x = load_image(x_path)\n",
    "result_x = sess.run(embeddings, feed_dict={single_image : image_x})\n",
    "result_x = result_x[0]\n",
    "\n",
    "distance_th = 1.2 # 거리가 얼마 미만이어야 나로 분류할지\n",
    "\n",
    "distance1 = calc_distance(embed_me[0], result_x)\n",
    "distance2 = calc_distance(embed_me[3], result_x)\n",
    "\n",
    "avg_distance = (distance1 + distance2)/2\n",
    "print(\"distance:\", avg_distance)\n",
    "\n",
    "if(avg_distance < distance_th):\n",
    "    print(x_path, \"는 내 얼굴입니다.\")\n",
    "else :\n",
    "    print(x_path, \"는 내 얼굴이 아닙니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단일 RGB영상과 pre-trained 네트워크(P/R/O net)를 입력받아\n",
    "# 1. face detection\n",
    "# 2. crop(margin추가)\n",
    "# 3. resize 하고\n",
    "# 검출된 얼굴 영상들의 리스트를 반환하는 함수\n",
    "\n",
    "def crop_faces(image, pnet, rnet, onet) :\n",
    "    # face detection 관련 파라미터\n",
    "    minsize = 20 # minimum size of face\n",
    "    threshold = [0.3, 0.3, 0.3] # thress step's threshold\n",
    "    factor = 0.709 # scale factor\n",
    "    ##################################################\n",
    "    \n",
    "    # crop 관련 파라미터\n",
    "    margin = 44 # 상하좌우 여백\n",
    "    image_size = 160 # resize(scaling) 크기\n",
    "    \n",
    "    h,w,_ = np.shape(image)\n",
    "    \n",
    "    # 얼굴 검출\n",
    "    bounding_boxes, points = detect_face.detect_face(image, minsize, pnet, rnet, onet, threshold, factor)\n",
    "    # bounding_boxes : 검출된 사각형 영역, [x1, y1, x2, y2, 확률]로 이루어진 리스트\n",
    "    # points : 검출된 얼굴의 주요 landmark [x1, x2, x3, x4, x5, y1, y2, y3, y4, y5]로 이루어진 리스트\n",
    "    \n",
    "    faces = []\n",
    "    for box in bounding_boxes :\n",
    "        box = np.int32(box)\n",
    "        bb = np.zeros(4, dtype=np.int32)\n",
    "        bb[0] = np.maximum(box[0] - margin/2, 0)\n",
    "        bb[1] = np.maximum(box[1] - margin/2, 0)\n",
    "        bb[2] = np.maximum(box[2] - margin/2, w)\n",
    "        bb[3] = np.maximum(box[3] - margin/2, h)\n",
    "        cropped = image[bb[1]:bb[3], bb[0]:bb[2], :]\n",
    "        scaled = cv2.resize(cropped, (image_size, image_size), interpolation=cv2.INTER_LINEAR)\n",
    "        \n",
    "        faces.append(scaled)\n",
    "        \n",
    "    return faces, bounding_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#얼굴인식(사진)\n",
    "#영상을 입력받아 face detection을 수행하고,\n",
    "#얼굴 영역에 네모를 그려 return 해주는 함수\n",
    "\n",
    "# def FaceDetection(img):\n",
    "#     color = (255,0,0) # 얼굴 영역을 표시할 네모의 색상 지정\n",
    "#     thickness = 2 # 네모의 두께\n",
    "    \n",
    "#     result_img = img.copy()\n",
    "    \n",
    "#     gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "#     #이미 학습되어있는 Haar Cascade Classifier 로드\n",
    "#     face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "    \n",
    "#     #얼굴 검출 수행\n",
    "#     faces = face_cascade.detectMultiScale(gray_img, 1.1, 5)\n",
    "    \n",
    "#     #검출된 얼굴 영역 그리기\n",
    "#     for (x,y,w,h) in faces:\n",
    "#         cv2.rectangle(result_img, (x,y),(x+w, y+h), color, 2)\n",
    "#     return result_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import cv2\n",
    "\n",
    "# #얼굴인식(사진)\n",
    "# #영상을 입력받아 face detection을 수행하고,\n",
    "# #얼굴 영역에 네모를 그려 return 해주는 함수\n",
    "\n",
    "# def FaceDetection(img):\n",
    "#     color = (255,0,0) # 얼굴 영역을 표시할 네모의 색상 지정\n",
    "#     thickness = 2 # 네모의 두께\n",
    "    \n",
    "#     result_img = img.copy()\n",
    "    \n",
    "#     gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "#     #이미 학습되어있는 Haar Cascade Classifier 로드\n",
    "#     face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "# #     face_cascade = crop_faces(frame, pnet, rnet, onet)\n",
    "# #     b = face_cascade[0]\n",
    "    \n",
    "#     #얼굴 검출 수행\n",
    "#     faces = face_cascade.detectMultiScale(gray_img, 1.1, 5)\n",
    "# #     faces = b.detectMultiScale(gray_img, 1.1, 5)\n",
    "    \n",
    "#     #검출된 얼굴 영역 그리기\n",
    "#     for (x,y,w,h) in faces:\n",
    "#         cv2.rectangle(result_img, (x,y),(x+w, y+h), color, 2)\n",
    "#     return result_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8394981026649475\n",
      "1.1163462400436401\n",
      "1.0804377794265747\n",
      "0.7211267352104187\n",
      "0.6977840662002563\n",
      "0.6830697059631348\n",
      "0.6918385028839111\n",
      "0.6901257634162903\n",
      "0.6942076683044434\n",
      "0.7951970100402832\n",
      "0.755373477935791\n",
      "0.770206093788147\n",
      "0.7385790348052979\n",
      "0.6681404709815979\n",
      "0.7053770422935486\n",
      "0.6542114019393921\n",
      "0.6383682489395142\n",
      "0.7319139242172241\n",
      "0.783271074295044\n",
      "0.7616527080535889\n",
      "0.7213131189346313\n",
      "0.7703577280044556\n",
      "0.7437387108802795\n",
      "0.7347390651702881\n",
      "0.809743344783783\n",
      "1.2797560691833496\n",
      "0.9648399353027344\n",
      "1.2135839462280273\n",
      "1.2658991813659668\n",
      "1.062312126159668\n",
      "1.0540218353271484\n",
      "1.3238216638565063\n",
      "1.063449740409851\n",
      "1.3325917720794678\n",
      "1.4014954566955566\n",
      "1.330383062362671\n",
      "1.040412425994873\n",
      "1.3163728713989258\n",
      "1.1127784252166748\n",
      "1.3237251043319702\n",
      "1.1065723896026611\n",
      "1.3510847091674805\n",
      "1.0473326444625854\n",
      "1.3549058437347412\n",
      "1.0813581943511963\n",
      "1.359134316444397\n",
      "1.0567774772644043\n",
      "1.3367595672607422\n",
      "1.0983474254608154\n",
      "1.3386644124984741\n",
      "1.1068179607391357\n",
      "1.343083143234253\n",
      "1.474327802658081\n",
      "1.1225076913833618\n",
      "1.3493313789367676\n",
      "1.1182392835617065\n",
      "1.3444026708602905\n",
      "1.1240381002426147\n",
      "1.3580124378204346\n",
      "1.1524600982666016\n",
      "1.31325364112854\n",
      "1.1626449823379517\n",
      "1.243074893951416\n",
      "1.1232924461364746\n",
      "1.1913156509399414\n",
      "1.2540781497955322\n",
      "1.0873990058898926\n",
      "1.2018930912017822\n",
      "1.3562791347503662\n",
      "1.0071594715118408\n",
      "1.43013334274292\n",
      "1.4350271224975586\n",
      "0.8480628132820129\n",
      "1.2742736339569092\n",
      "1.2678066492080688\n",
      "1.0095551013946533\n",
      "1.3117992877960205\n",
      "1.0554563999176025\n",
      "1.2781397104263306\n",
      "1.2200982570648193\n",
      "1.0442352294921875\n",
      "1.2335259914398193\n",
      "1.3546454906463623\n",
      "1.0983703136444092\n",
      "1.1468919515609741\n",
      "1.1069834232330322\n",
      "0.9618202447891235\n",
      "1.3733407258987427\n",
      "1.4191573858261108\n",
      "1.0610921382904053\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-c30181e7df02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m225\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#     detected_faces = FaceDetection(frame)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mfaces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbounding_boxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrop_faces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#     cv2.imshow(\"frame\", frame)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-42e7fbd37c1c>\u001b[0m in \u001b[0;36mcrop_faces\u001b[0;34m(image, pnet, rnet, onet)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# 얼굴 검출\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mbounding_boxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect_face\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect_face\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;31m# bounding_boxes : 검출된 사각형 영역, [x1, y1, x2, y2, 확률]로 이루어진 리스트\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# points : 검출된 얼굴의 주요 landmark [x1, x2, x3, x4, x5, y1, y2, y3, y4, y5]로 이루어진 리스트\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Week9+hw3/src/align/detect_face.py\u001b[0m in \u001b[0;36mdetect_face\u001b[0;34m(img, minsize, pnet, rnet, onet, threshold, factor)\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0mimg_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0mimg_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m         \u001b[0mout0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0mout1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Week9+hw3/src/align/detect_face.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0monet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'det3.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m     \u001b[0mpnet_fun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pnet/conv4-2/BiasAdd:0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pnet/prob1:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'pnet/input:0'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m     \u001b[0mrnet_fun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rnet/conv5-2/conv5-2:0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rnet/prob1:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'rnet/input:0'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0monet_fun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'onet/conv6-2/conv6-2:0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'onet/conv6-3/conv6-3:0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'onet/prob1:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'onet/input:0'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#얼굴인식(캠)\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    frame = cv2.resize(frame,(400,225))\n",
    "#     detected_faces = FaceDetection(frame)\n",
    "    faces, bounding_boxes = crop_faces(frame, pnet, rnet, onet)\n",
    "    \n",
    "#     cv2.imshow(\"frame\", frame)\n",
    "#     cv2.imshow(\"detected\", frame)\n",
    "    \n",
    "    squared_img = frame.copy()\n",
    "    for i in range(len(bounding_boxes)):\n",
    "        box=bounding_boxes[i]\n",
    "        face=faces[i]\n",
    "        box = np.int32(box)\n",
    "        p1 = (box[0], box[1])\n",
    "        p2 = (box[2], box[3])\n",
    "\n",
    "        result_x = sess.run(embeddings, feed_dict={single_image : face})\n",
    "        result_x = result_x[0]\n",
    "        distance_th = 1.2 # 거리가 얼마 미만이어야 나로 분류할지\n",
    "        distance1 = calc_distance(embed_me[0], result_x)\n",
    "        distance2 = calc_distance(embed_me[3], result_x)\n",
    "        avg_distance = (distance1 + distance2)/2\n",
    "#         print(\"distance:\", avg_distance)\n",
    "        if(avg_distance < distance_th):\n",
    "            cv2.rectangle(squared_img, p1, p2, color=(0,255,0))\n",
    "            cv2.imshow(' ', squared_img)\n",
    "        else :\n",
    "            cv2.rectangle(squared_img, p1, p2, color=(0,0,255))\n",
    "            cv2.imshow(' ', squared_img)\n",
    "#         cv2.rectangle(squared_img, p1, p2, color=(255,0,0))\n",
    "        print(avg_distance)\n",
    "        \n",
    "        \n",
    "#     cv2.imshow(' ', squared_img)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "for i in range(1,5):\n",
    "    cv2.waitkey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance: 1.7397706508636475\n",
      "./data/faces/me/video_bc2_short0_0.jpg 는 내 얼굴이 아닙니다.\n"
     ]
    }
   ],
   "source": [
    "#내 얼굴인지 분류\n",
    "# 영상 경로를 자유롭게 수정\n",
    "x_path = \"./data/faces/me/video_bc2_short0_0.jpg\"\n",
    "\n",
    "image_x = load_image(x_path)\n",
    "result_x = sess.run(embeddings, feed_dict={single_image : image_x})\n",
    "result_x = result_x[0]\n",
    "\n",
    "distance_th = 1.2 # 거리가 얼마 미만이어야 나로 분류할지\n",
    "\n",
    "distance1 = calc_distance(embed_me[0], result_x)\n",
    "distance2 = calc_distance(embed_me[3], result_x)\n",
    "\n",
    "avg_distance = (distance1 + distance2)/2\n",
    "print(\"distance:\", avg_distance)\n",
    "\n",
    "if(avg_distance < distance_th):\n",
    "    print(x_path, \"는 내 얼굴입니다.\")\n",
    "else :\n",
    "    print(x_path, \"는 내 얼굴이 아닙니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Required argument 'mat' (pos 2) not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-7a9714642c2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msquared_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msquared_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;36m0xFF\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'q'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Required argument 'mat' (pos 2) not found"
     ]
    }
   ],
   "source": [
    "# #얼굴인식 (동영상)\n",
    "\n",
    "# import numpy as np\n",
    "# import cv2\n",
    "\n",
    "# cap = cv2.VideoCapture(\"me.mp4\")\n",
    "\n",
    "# while(cap.isOpened()):\n",
    "#     ret, frame = cap.read()\n",
    "    \n",
    "#     frame = cv2.resize(frame, (400,225))\n",
    "    \n",
    "# #     detected_faces = FaceDetection(frame)\n",
    "#     faces, bounding_boxes = crop_faces(frame, pnet, rnet, onet)\n",
    "#     cv2.imshow(\"frame\", frame)\n",
    "# #     cv2.imshow(\"detected\", faces)\n",
    "    \n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "    \n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(3.4.2) /opt/concourse/worker/volumes/live/9523d527-1b9e-48e0-7ed0-a36adde286f0/volume/opencv-suite_1535558719691/work/modules/imgproc/src/color.hpp:253: error: (-215:Assertion failed) VScn::contains(scn) && VDcn::contains(dcn) && VDepth::contains(depth) in function 'CvtHelper'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-a914c967b1a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"me.mp4\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# plt.figure()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# plt.imshow(image)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfaces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbounding_boxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrop_faces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-c1959ece189f>\u001b[0m in \u001b[0;36mload_image\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(3.4.2) /opt/concourse/worker/volumes/live/9523d527-1b9e-48e0-7ed0-a36adde286f0/volume/opencv-suite_1535558719691/work/modules/imgproc/src/color.hpp:253: error: (-215:Assertion failed) VScn::contains(scn) && VDcn::contains(dcn) && VDepth::contains(depth) in function 'CvtHelper'\n"
     ]
    }
   ],
   "source": [
    "image = load_image(\"me.mp4\")\n",
    "# plt.figure()\n",
    "# plt.imshow(image)\n",
    "\n",
    "faces, bounding_boxes = crop_faces(image, pnet, rnet, onet)\n",
    "print(\"영상에서 검출된 얼굴의 개수:\", len(faces))\n",
    "\n",
    "# plt.figure()\n",
    "# plt.imshow(faces[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bounding_boxes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d3f28ab8c7a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msquared_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbox\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbounding_boxes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bounding_boxes' is not defined"
     ]
    }
   ],
   "source": [
    "squared_img = cv2.VideoCapture(0)\n",
    "for box in bounding_boxes:\n",
    "    box = np.int32(box)\n",
    "    p1 = (box[0], box[1])\n",
    "    p2 = (box[2], box[3])\n",
    "    cv2.rectangle(squared_img, p1, p2, color=(255,0,0))\n",
    "cv2.imshow(squared_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
